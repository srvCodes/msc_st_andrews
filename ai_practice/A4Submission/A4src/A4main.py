import pandas as pd
from src import encodeData, neuralNetwork, createNewDataset, daysOutputNeuralNet
from sklearn.model_selection import train_test_split
import numpy as np
import pickle
import sys
import os
from sklearn.svm import SVC

training_data = pd.DataFrame()


def readCsvFile():
    df = pd.read_csv('tickets.csv', encoding='utf-8')
    return df


def get_features_and_labels(df):
    """
    Function to separate features and labels from the dataframe.
    @param df: is the dataframe read from the csv file.
    @return: a tuple of two lists: (features, labels)
    """
    all_values = df.values.tolist()
    x = [np.array(each[:-1]) for each in all_values]
    if isinstance(all_values[0][-1], int):
        y = [np.array(each[-1:]) for each in all_values]
    else:
        y = [each[-1:][0] for each in all_values]
    return (x, y)


def create_training_table(X, y, column_names, initialize_mode=False):
    """
    Function to create and modify the data used for training the neural networks.
    @param X: is the list of features.
    @param y: is the list of corresponding labels.
    @param column_names: is the list of feature names.
    @param initialize_mode: is true when the network is trained for the first time, i.e. no chance of modification.
    @return: list of features and modified labels.
    """
    global training_data
    complete_list = []
    for index, element in enumerate(X):
        complete_list.append(element.tolist())
        complete_list[index].append(y[index])
    if not initialize_mode:
        # simply save the data to file
        training_data = pd.DataFrame(complete_list)
        training_data.columns = column_names
        training_data.to_csv('training_table.csv', index=False)
    else:
        # replace the existing entry if found
        relevant_columns = np.array(complete_list[0][:-1])
        if (training_data[training_data.columns[:-1]] == relevant_columns).all(1).any():
            matching_index = training_data[(training_data['Request'] == complete_list[0][0]) &
                                           (training_data['Incident'] == complete_list[0][1]) &
                                           (training_data['WebServices'] ==
                                            complete_list[0][2]) & (training_data['Login'] == complete_list[0][3]) & (
                                                   training_data['Wireless'] == complete_list[0][4]) &
                                           (training_data['Printing'] == complete_list[0][5]) & (
                                                   training_data['IdCards'] == complete_list[0][6]) & (
                                                   training_data['Staff'] ==
                                                   complete_list[0][7]) & (
                                                   training_data['Students'] == complete_list[0][
                                               8])].index.values.astype(int)
            print(f"Found matching entries in columns: {matching_index}. Updating their labels now..")
            print("Putting entries into training table. You can view them in the file 'modified_training_table.csv'..")

            for index in matching_index:
                # set the label for all matching indices to the new label.
                training_data.set_value(index, 'Response Team',
                                        np.array(complete_list[0][-1]))
        else:
            print(f"No matching entries found in training table with same feature set. Appending this to the end of training dataframe.")
            training_data.append(pd.Series(complete_list[0], index=column_names), ignore_index=True)
            print("You can view them in the file 'modified_training_table.csv'..")
        training_data.columns = column_names
        training_data.to_csv('modified_training_table.csv', index=False)
    X, y = get_features_and_labels(training_data)
    return X, y


def get_max_index(array_of_arrays):
    """
    Function to get the index of greatest element in array.
    @param array_of_arrays: array of array of probabilities generated by softmax function.
    @return: array of indices of max element in each array.
    """
    index_of_max_elements = []
    for array in array_of_arrays:
        max_index = np.where(array == array.max())
        # print(type(max_index))  # max_index is a tuple of form ==> (array(index with max val), )
        index_of_max_elements.append(max_index[0].tolist()[0])
    return index_of_max_elements


def get_decoded_output(encoded_output_list):
    """
    Function to decode the output of network to obtain the corresponding class name.
    @param encoded_output_list: a list whose each element is the predicted label for a set of features.
    @return: list of decoded class names.
    """
    output_label_encoder = pickle.load(open('labelEncoder_Response.pkl', 'rb'))
    print(f"Original mapping of classes-to-labels: {output_label_encoder}")
    reversed_dict = dict(map(reversed, output_label_encoder.items()))
    print(f"Reversed mapping of classes:  {reversed_dict}")
    print(f"Predicted encoded output: {encoded_output_list}")
    decoded_labels = np.asarray([reversed_dict[i] for i in encoded_output_list])
    return decoded_labels


def trigger_text_interface(advanced=False, problem=None, svm = None):
    """
    Function to trigger the text UI in order to receive input from user and perform inference.
    @param advanced: is false for basic and intermediate agents.
    @param problem: possible values are 1/2 when an advanced agent is requested.
    @return: list of encoded features and the output.
    """
    interface = encodeData.TextInterface(training_data)
    encoded_data = interface.encode_user_data()
    encoded_data = encoded_data.transpose()

    network = neuralNetwork.FeedForwardNetwork(encoded_data, load_from_file=True)
    predicted_output = network.predict(encoded_data)
    result = get_max_index(predicted_output)
    labelled_result = get_decoded_output(result)
    print("\n========================================\n")
    print(f'1.  Decoded answer for team handling the response (using basic agent): "{labelled_result[0]}"')

    if advanced:
        if problem == "1":
            network = daysOutputNeuralNet.FeedForwardNetwork(encoded_data, load_from_file=True)
            predicted_days = network.predict(encoded_data)[0][0]
            print(f'2.  Number of days required to resolve the issue: "{(int)(predicted_days)}"')
        elif problem == "2":
            network = neuralNetwork.FeedForwardNetwork(encoded_data, load_from_file=True, advanced=True)
            _predicted_output = network.predict(encoded_data)
            _result = get_max_index(_predicted_output)
            _labelled_result = get_decoded_output(_result)
            print(f'2.  Decoded answer for team handling the response (using minibatch gradient descent): '
                  f'"{_labelled_result[0]}"')
            svm_output = get_decoded_output(svm.predict(encoded_data))
            print(f'3.  Output of support vector machine: "{svm_output[0]}"')
    print("\n=======================================\n")
    return [encoded_data, labelled_result]


def train_loop(X, y, compute_day=False, advanced=False):
    """
    Function to perform training and testing.
    @param X: are features obtained from csv file.
    @param y: are labels corresponding to features.
    @param compute_day: is true if day is to be predicted.
    @param advanced: is true if advanced agent requested.
    @return: None
    """
    print("Training the network now.. ")
    x_trainval, x_test, y_trainval, y_test = train_test_split(np.array(X), np.array(y), test_size=0.2,
                                                      random_state=20)
    x_train, x_val, y_train, y_val = train_test_split(x_trainval, y_trainval, test_size=0.2, random_state=20)
    if compute_day:
        print("\nInitializing and training the regression neural net for predicting days.. \n")
        my_network = daysOutputNeuralNet.FeedForwardNetwork(x_train, y_train, x_val, y_val)
        my_network.train()
    else:
        if advanced and not compute_day:
            print("\nInitializing and training the neural net using mini-batch gradient descent.. \n")
            my_network = neuralNetwork.FeedForwardNetwork(x_train, y_train, x_val, y_val, advanced=True)
            my_network.train_minibatch()
        else:
            my_network = neuralNetwork.FeedForwardNetwork(x_train, y_train, x_val, y_val)
            my_network.train()
    print("\n\nRunning the prediction and evaluation on the test set.. ")
    _ = my_network.test(x_test, y_test)


def main():
    """
    Main method. Accepts command line argument and triggers the basic/intermediate/advanced agents accordingly.
    Example: python3 A4main.py Adv 1
    """
    global training_data
    MODE = sys.argv[1]
    mode_dict = {'Adv': 'Advanced', 'Bas': 'Basic', 'Int': 'Intermmediate'}
    print(f"Mode requested: {mode_dict.get(MODE)}")
    pandas_dataframe = readCsvFile()
    data_encoder = encodeData.DataEncoder()
    label_encoded_df = data_encoder.label_encode_columns(pandas_dataframe, load_from_file=False)
    training_data = label_encoded_df
    X, label_encoded_y = get_features_and_labels(label_encoded_df)
    one_hot_encoded_y = data_encoder.manual_one_hot_encoder(label_encoded_y)
    _ = create_training_table(X, one_hot_encoded_y, list(pandas_dataframe.columns), initialize_mode=False)

    problem = None
    if MODE == "Bas":
        # train the network if basic agent requested, also show the test error on the test set
        train_loop(X, one_hot_encoded_y)
    elif MODE == "Int" or MODE == "Adv":
        # trigger the text interface if intermediate or advanced agent requested
        if MODE == "Adv":
            # do additional stuffs if advanced agent requested
            path = './'
            pickle_files = [f for f in os.listdir(path) if f.endswith('.pkl')] # get list of all pickle files saved
            problem = sys.argv[2]
            if problem == "1":
                # if network not trained before, train it
                if "network_config_2.pkl" not in pickle_files:
                    # create dataset for days
                    new_df = createNewDataset.returnNewDf(label_encoded_df)
                    X_new, y_new = get_features_and_labels(new_df)
                    train_loop(X_new, y_new, compute_day=True)
            elif problem == "2":
                if "network_config_3.pkl" not in pickle_files:
                    X, y = get_features_and_labels(label_encoded_df)
                    one_hot_encoded_y = data_encoder.manual_one_hot_encoder(y)
                    train_loop(X, one_hot_encoded_y, advanced=True)
                svm = SVC()
                print("Training svm.. ")
                svm.fit(X, label_encoded_y)
        while (True):
            user_input = input("\nWant to handle a new ticket? Press 'y' or 'n': ")
            # user_input = 'y'
            if (user_input == 'n'):
                break
            if MODE == "Adv" and problem == "2":
                test_tags, predicted_answer = trigger_text_interface(advanced=MODE == "Adv", problem=problem, svm=svm)
            else:
                test_tags, predicted_answer = trigger_text_interface(advanced=MODE == "Adv", problem=problem)
            user_feedback = input("Press 'y' if you are happy with the result, press 'n' otherwise: ")
            # user_feedback = 'n'
            if user_feedback == 'y':
                continue
            actual_answer = input("Enter the correct team name that you think should handle the ticket: ")
            # actual_answer = 'Equipment'
            label_encoded_answer = data_encoder.encode_labels([actual_answer], "Response Team", load_from_file=True)
            one_hot_encoded_answer = data_encoder.manual_one_hot_encoder([np.asarray(label_encoded_answer)],
                                                                         new_entry=True)
            X, label_encoded_y = create_training_table(test_tags, one_hot_encoded_answer, list(pandas_dataframe.columns),
                                         initialize_mode=True)
            train_loop(X, label_encoded_y)

if __name__ == "__main__":
    main()
